{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignments Machine learning\n",
    "- Sophie\n",
    "- Emmelien\n",
    "- Isabelle\n",
    "- Daan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "def find(name, path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "path = os.path.dirname(os.path.abspath(\"ml_final\"))\n",
    "path_data = find(\"empdata.csv\", path)\n",
    "data = pd.read_csv(path_data)\n",
    "        \n",
    "col_headers = list(data.columns.values)\n",
    "# print (col_headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                         False\n",
      "Attrition                   False\n",
      "BusinessTravel              False\n",
      "DailyRate                   False\n",
      "Department                  False\n",
      "DistanceFromHome            False\n",
      "Education                   False\n",
      "EducationField              False\n",
      "EmployeeCount               False\n",
      "EmployeeNumber              False\n",
      "EnvironmentSatisfaction     False\n",
      "Gender                      False\n",
      "HourlyRate                  False\n",
      "JobInvolvement              False\n",
      "JobLevel                    False\n",
      "JobRole                     False\n",
      "JobSatisfaction             False\n",
      "MaritalStatus               False\n",
      "MonthlyIncome               False\n",
      "MonthlyRate                 False\n",
      "NumCompaniesWorked          False\n",
      "Over18                      False\n",
      "OverTime                    False\n",
      "PercentSalaryHike           False\n",
      "PerformanceRating           False\n",
      "RelationshipSatisfaction    False\n",
      "StandardHours               False\n",
      "StockOptionLevel            False\n",
      "TotalWorkingYears           False\n",
      "TrainingTimesLastYear       False\n",
      "WorkLifeBalance             False\n",
      "YearsAtCompany              False\n",
      "YearsInCurrentRole          False\n",
      "YearsSinceLastPromotion     False\n",
      "YearsWithCurrManager        False\n",
      "dtype: bool\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Missing values and imputing\n",
    "print(data.isnull().any())\n",
    "print(data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing the dataset\n",
    "# Todo\n",
    "# - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 0 0]\n",
      "['Non-Travel', 'Travel_Frequently', 'Travel_Rarely']\n",
      "['Human Resources', 'Research & Development', 'Sales']\n",
      "['Human Resources', 'Life Sciences', 'Marketing', 'Medical', 'Other', 'Technical Degree']\n",
      "['Female', 'Male']\n",
      "['Healthcare Representative', 'Human Resources', 'Laboratory Technician', 'Manager', 'Manufacturing Director', 'Research Director', 'Research Scientist', 'Sales Executive', 'Sales Representative']\n",
      "['Divorced', 'Married', 'Single']\n",
      "['No', 'Yes']\n",
      "{'BusinessTravel': LabelEncoder(), 'Department': LabelEncoder(), 'EducationField': LabelEncoder(), 'Gender': LabelEncoder(), 'JobRole': LabelEncoder(), 'MaritalStatus': LabelEncoder(), 'OverTime': LabelEncoder()}\n",
      "{'BusinessTravel': array([2, 1, 2, ..., 2, 1, 2]), 'Department': array([2, 1, 1, ..., 1, 2, 1]), 'EducationField': array([1, 1, 4, ..., 1, 3, 3]), 'Gender': array([0, 1, 1, ..., 1, 1, 1]), 'JobRole': array([7, 6, 2, ..., 4, 7, 2]), 'MaritalStatus': array([2, 1, 2, ..., 1, 1, 1]), 'OverTime': array([1, 0, 1, ..., 1, 0, 0])}\n",
      "Age                         False\n",
      "DailyRate                   False\n",
      "DistanceFromHome            False\n",
      "Education                   False\n",
      "EmployeeCount               False\n",
      "EmployeeNumber              False\n",
      "EnvironmentSatisfaction     False\n",
      "HourlyRate                  False\n",
      "JobInvolvement              False\n",
      "JobLevel                    False\n",
      "JobSatisfaction             False\n",
      "MonthlyIncome               False\n",
      "MonthlyRate                 False\n",
      "NumCompaniesWorked          False\n",
      "PercentSalaryHike           False\n",
      "PerformanceRating           False\n",
      "RelationshipSatisfaction    False\n",
      "StandardHours               False\n",
      "StockOptionLevel            False\n",
      "TotalWorkingYears           False\n",
      "TrainingTimesLastYear       False\n",
      "WorkLifeBalance             False\n",
      "YearsAtCompany              False\n",
      "YearsInCurrentRole          False\n",
      "YearsSinceLastPromotion     False\n",
      "YearsWithCurrManager        False\n",
      "BusinessTravel              False\n",
      "Department                  False\n",
      "EducationField              False\n",
      "Gender                      False\n",
      "JobRole                     False\n",
      "MaritalStatus               False\n",
      "OverTime                    False\n",
      "dtype: bool\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:116: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "atrittion = data.iloc[:,1:2]\n",
    "variables_ex_age = data.loc[:,list(data.columns[2:])]\n",
    "age = data.iloc[:, 0:1]\n",
    "atrittion12 = data.iloc[:,1:2]\n",
    "x = le.fit(atrittion12).transform(atrittion12)\n",
    "\n",
    "\n",
    "\n",
    "list_strings = [\"BusinessTravel\", \"Department\", \"EducationField\", \"Gender\", \"JobRole\", \"MaritalStatus\",  \"OverTime\"]\n",
    "\n",
    "all_vars = pd.concat([age, variables_ex_age], axis=1)\n",
    "# over 18 has one value so drop\n",
    "all_varsnew = all_vars.drop([\"Over18\"], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dicci ={}\n",
    "dicci2 ={}\n",
    "lissa = []\n",
    "le = preprocessing.LabelEncoder()\n",
    "atrittion1 = le.fit(atrittion[\"Attrition\"])\n",
    "atrittion2 = le.transform(atrittion[\"Attrition\"])\n",
    "print (atrittion2)\n",
    "for names in list_strings:\n",
    "    dicci[names]= le.fit(all_varsnew[names])\n",
    "    \n",
    "    print(list(le.classes_))\n",
    "    dicci2[names] = le.transform(all_varsnew[names])\n",
    "    lissa.append(dicci2[names])\n",
    "\n",
    "no_cat_vars = all_varsnew.drop(all_vars1.ix[:,list_strings].head(0).columns, axis=1)  \n",
    "  \n",
    "cat_vars = pd.DataFrame.from_dict(dicci2)\n",
    "\n",
    "all_vars_pp = pd.concat([no_cat_vars,cat_vars], axis = 1)\n",
    "print (dicci)\n",
    "print (dicci2)\n",
    "print(all_vars_pp.isnull().any())\n",
    "print(all_vars_pp.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X, y = all_vars_pp, atrittion2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 33)\n",
      "(338, 33)\n",
      "[169 169]\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "# Undersampeling\n",
    "\n",
    "rus = RandomUnderSampler(replacement=False)\n",
    "\n",
    "\n",
    "X_train_subsample, y_train_subsample = rus.fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_subsample.shape)\n",
    "print(np.bincount(y_train_subsample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegressionCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-f18dceddb649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmake_imb_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mundersample_pipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_imb_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundersample_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegressionCV' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\daan_\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,MaxAbsScaler, RobustScaler\n",
    "\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaler3 = MaxAbsScaler()\n",
    "scaler2 = RobustScaler()\n",
    "X_train_scaled1 = scaler1.fit_transform(X_train)\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train)\n",
    "X_train_scaled3 = scaler3.fit_transform(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# y_train_scaled = scaler.fit_transform(y_train)\n",
    "\n",
    "scale_list = []\n",
    "scale_list.append(X_train_scaled)\n",
    "scale_list.append(X_train_scaled1)\n",
    "scale_list.append(X_train_scaled2)\n",
    "scale_list.append(X_train_scaled3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 28, 22, 13, 32, 29,  6, 27,  3,  4,  7, 30, 31, 11, 18, 15,  9,\n",
       "       33, 10, 19, 14, 12, 21, 20, 17, 16, 26,  5, 23,  8, 24,  2,  1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# create ranking among all features by selecting only one\n",
    "rfe = RFE(LinearRegression(), n_features_to_select=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set val set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
